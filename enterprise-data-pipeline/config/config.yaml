# Enterprise Data Pipeline Configuration
# This file contains all configuration parameters for the pipeline

# API Configuration
api:
  coingecko:
    base_url: "https://api.coingecko.com/api/v3"
    endpoints:
      markets: "/coins/markets"
      trending: "/search/trending"
    params:
      vs_currency: "usd"
      order: "market_cap_desc"
      per_page: 100
      page: 1
    rate_limit_per_minute: 50
    timeout: 30
    retry_attempts: 3
    retry_delay: 5

# Databricks Configuration
databricks:
  workspace_url: "${DATABRICKS_WORKSPACE_URL}"
  token: "${DATABRICKS_TOKEN}"
  cluster_id: "${DATABRICKS_CLUSTER_ID}"
  
  # Spark Configuration
  spark:
    app_name: "CryptoDataPipeline"
    shuffle_partitions: 200
    adaptive_enabled: true
    
  # Storage paths
  storage:
    bronze_path: "dbfs:/mnt/data/bronze/crypto"
    silver_path: "dbfs:/mnt/data/silver/crypto"
    gold_path: "dbfs:/mnt/data/gold/crypto"
    checkpoint_path: "dbfs:/mnt/data/checkpoints/crypto"

# Snowflake Configuration
snowflake:
  account: "${SNOWFLAKE_ACCOUNT}"
  user: "${SNOWFLAKE_USER}"
  password: "${SNOWFLAKE_PASSWORD}"  # Leave empty if using externalbrowser
  authenticator: "${SNOWFLAKE_AUTHENTICATOR:-externalbrowser}"
  warehouse: "${SNOWFLAKE_WAREHOUSE}"
  database: "${SNOWFLAKE_DATABASE:-CRYPTO_DB}"
  schema: "${SNOWFLAKE_SCHEMA:-PUBLIC}"
  role: "${SNOWFLAKE_ROLE:-ACCOUNTADMIN}"
  
  # Tables
  tables:
    silver: "silver_crypto_clean"
    gold: "gold_crypto_metrics"
    metadata: "pipeline_metadata"
  
  # Loading options
  loading:
    mode: "incremental"  # incremental or full
    merge_key: "coin_id"
    batch_size: 5000

# Data Quality Rules
data_quality:
  validation_rules:
    - name: "check_nulls"
      columns: ["coin_id", "symbol", "current_price"]
      type: "not_null"
    - name: "check_price_range"
      column: "current_price"
      type: "range"
      min: 0
      max: 1000000
    - name: "check_market_cap"
      column: "market_cap"
      type: "positive"
    - name: "check_volume"
      column: "total_volume"
      type: "positive"
  
  anomaly_detection:
    enabled: true
    price_change_threshold: 0.5  # 50% change flag
    volume_spike_threshold: 3  # 3x standard deviation

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    file:
      enabled: true
      path: "logs/pipeline.log"
      max_bytes: 10485760  # 10MB
      backup_count: 5
    console:
      enabled: true

# Airflow Configuration
airflow:
  dag_id: "enterprise_crypto_pipeline"
  schedule: "0 */4 * * *"  # Every 4 hours
  start_date: "2024-01-01"
  catchup: false
  max_active_runs: 1
  retries: 3
  retry_delay: 300  # 5 minutes
  email_on_failure: true
  email_on_retry: false
  sla: 3600  # 1 hour

# Monitoring & Alerting
monitoring:
  enabled: true
  metrics:
    - records_processed
    - processing_time
    - error_rate
    - data_quality_score
  alerts:
    email: "${ALERT_EMAIL}"
    slack_webhook: "${SLACK_WEBHOOK_URL}"
