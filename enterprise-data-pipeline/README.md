# ğŸš€ Enterprise Data Pipeline: CoinGecko API â†’ Databricks â†’ Snowflake

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![PySpark](https://img.shields.io/badge/PySpark-3.5+-orange.svg)
![Databricks](https://img.shields.io/badge/Databricks-Community-red.svg)
![Snowflake](https://img.shields.io/badge/Snowflake-Cloud_DW-blue.svg)
![Azure](https://img.shields.io/badge/Azure-Key_Vault-blue.svg)
![Security](https://img.shields.io/badge/Security-Enterprise_Grade-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ Overview

**Enterprise-grade** data pipeline that extracts cryptocurrency data from CoinGecko API, processes with PySpark on Databricks Community Edition, and loads into Snowflake following the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold).

ğŸ¯ **Extracts** data from CoinGecko API  
âš™ï¸ **Processes** with PySpark on Databricks (Bronze â†’ Silver â†’ Gold)  
ğŸ“Š **Stores** in Snowflake with optimized layers  
ğŸ” **Secure** with Azure Key Vault for credentials  

### ğŸŒŸ Technical Highlights

- âœ… **Medallion Architecture**: Bronze (raw), Silver (cleaned), Gold (aggregated)
- âœ… **Azure Key Vault**: Secure credential management with Service Principal
- âœ… **Type 2 SCD**: Complete change history in Silver layer
- âœ… **Snowflake VARIANT**: Flexible JSON storage in Bronze
- âœ… **Modularity**: Organized code (extractors/transformers/utils)
- âœ… **Structured Logging**: Complete execution tracking
- âœ… **Databricks Community**: Optimized for Free Tier

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CoinGecko API v3                             â”‚
â”‚              (Cryptocurrency Market Data)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ“¥ EXTRACTION                                  â”‚
â”‚                 (notebooks/01_extraction.py)                     â”‚
â”‚         â€¢ Rate limiting  â€¢ Retry logic  â€¢ Azure Key Vault       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             ğŸ¥‰ BRONZE LAYER (Snowflake)                         â”‚
â”‚          BRONZE.BRONZE_CRYPTO_RAW (VARIANT column)              â”‚
â”‚              Raw JSON, immutable, timestamped                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  âš™ï¸  TRANSFORMATION                              â”‚
â”‚              (notebooks/02_transformation.py)                    â”‚
â”‚    â€¢ PySpark processing  â€¢ Quality checks  â€¢ Aggregations      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¥ˆ SILVER LAYER           â”‚  â”‚   ğŸ¥‡ GOLD LAYER            â”‚
â”‚   (Snowflake)                â”‚  â”‚   (Snowflake)              â”‚
â”‚                              â”‚  â”‚                            â”‚
â”‚ SILVER.silver_crypto_clean   â”‚  â”‚ GOLD.gold_crypto_metrics   â”‚
â”‚ â€¢ Cleaned & validated        â”‚  â”‚ â€¢ Aggregated by category   â”‚
â”‚ â€¢ Type 2 SCD (is_current)    â”‚  â”‚ â€¢ Ready for BI             â”‚
â”‚ â€¢ Quality flags              â”‚  â”‚ â€¢ Optimized for analytics  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”‘ Layers (Medallion Architecture)

- **ğŸ¥‰ Bronze**: Raw JSON from API â†’ `BRONZE.BRONZE_CRYPTO_RAW` (VARIANT)
- **ğŸ¥ˆ Silver**: Clean and validated data â†’ `SILVER.silver_crypto_clean` (Type 2 SCD)
- **ğŸ¥‡ Gold**: Aggregated metrics â†’ `GOLD.gold_crypto_metrics` (KPIs by category)

---

## ğŸ“ Project Structure

```
enterprise-data-pipeline/
â”œâ”€â”€ ğŸ““ notebooks/                    # Databricks notebooks
â”‚   â”œâ”€â”€ 00_test_keyvault.py         # â†’ Azure Key Vault test
â”‚   â”œâ”€â”€ 01_extraction.py            # â†’ API extraction â†’ Snowflake Bronze
â”‚   â”œâ”€â”€ 02_transformation.py        # â†’ Bronze â†’ Silver â†’ Gold
â”‚   â””â”€â”€ 03_loading.py               # â†’ Validation and metadata
â”‚
â”œâ”€â”€ ğŸ src/                          # Python modules
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â””â”€â”€ coingecko_extractor.py  # â†’ APIExtractor class
â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â””â”€â”€ spark_processor.py      # â†’ SparkProcessor class
â”‚   â”œâ”€â”€ loaders/
â”‚   â”‚   â””â”€â”€ snowflake_loader.py     # â†’ SnowflakeLoader class
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logging_config.py       # â†’ Structured logging
â”‚       â””â”€â”€ config_loader.py        # â†’ Azure Key Vault integration
â”‚
â”œâ”€â”€ ğŸ—„ï¸  sql/
â”‚   â”œâ”€â”€ bronze_schema_setup.sql     # â†’ Bronze layer tables/views
â”‚   â””â”€â”€ snowflake_models.sql        # â†’ Silver/Gold tables/views
â”‚
â”œâ”€â”€ âš™ï¸  config/
â”‚   â””â”€â”€ config.yaml                 # â†’ Pipeline configuration
â”‚
â”œâ”€â”€ requirements.txt                 # â†’ Python dependencies
â””â”€â”€ README.md                        # â†’ This file
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

- **Python 3.9+**
- **Databricks Account** (Community Edition)
- **Snowflake Account** (Free trial)
- **Azure Account** (for Key Vault)
- **CoinGecko API** (free)

### 2. Clone and Install

```bash
git clone <repository-url>
cd enterprise-data-pipeline
pip install -r requirements.txt
```

### 3. Configure Azure Key Vault

#### 3.1 Create Key Vault

```bash
az keyvault create \
  --name kv-crypto-pipeline \
  --resource-group rg-data-engineer \
  --location eastus
```

#### 3.2 Create Service Principal

```bash
az ad sp create-for-rbac --name sp-databricks-crypto
# Copy: appId, password, tenant
```

#### 3.3 Add Permissions

```bash
az role assignment create \
  --role "Key Vault Secrets User" \
  --assignee <appId> \
  --scope /subscriptions/<sub-id>/resourceGroups/rg-data-engineer/providers/Microsoft.KeyVault/vaults/kv-crypto-pipeline
```

#### 3.4 Add Secrets to Key Vault

**Snowflake credentials:**
```bash
az keyvault secret set --vault-name kv-crypto-pipeline --name snowflake-account --value "your-account"
az keyvault secret set --vault-name kv-crypto-pipeline --name snowflake-user --value "your-username"
az keyvault secret set --vault-name kv-crypto-pipeline --name snowflake-password --value "your-password"
```

**Service Principal credentials:**
```bash
az keyvault secret set --vault-name kv-crypto-pipeline --name azure-tenant-id --value "<your-tenant-id>"
az keyvault secret set --vault-name kv-crypto-pipeline --name azure-client-id --value "<your-client-id>"
az keyvault secret set --vault-name kv-crypto-pipeline --name azure-client-secret --value "<your-client-secret>"
```

### 4. Snowflake Setup

```sql
-- Execute bronze_schema_setup.sql
-- Execute snowflake_models.sql
```

### 5. Configure Credentials

Copy the example credentials file and fill with your values:

```bash
cd enterprise-data-pipeline/config
cp credentials.yaml.example credentials.yaml
# Edit credentials.yaml with your Azure Service Principal values
```

**credentials.yaml:**
```yaml
azure:
  tenant_id: "your-tenant-id"
  client_id: "your-client-id"
  client_secret: "your-client-secret"

key_vault:
  name: "kv-crypto-pipeline"
  url: "https://kv-crypto-pipeline.vault.azure.net/"
```

âš ï¸ **Important:** This file is in `.gitignore` and will NOT be committed to Git.

### 6. Deploy to Databricks

1. **Upload config folder** including `credentials.yaml` to `/Workspace/Users/<your-email>/data-engineer-portfolio/enterprise-data-pipeline/config/`
2. **Upload notebooks** from `notebooks/` folder to Databricks Workspace
3. **Upload modules** from `src/` folder to `/Workspace/Users/<your-email>/data-engineer-portfolio/enterprise-data-pipeline/src`
4. **Execute notebooks in order:**
   - `00_test_keyvault.py` (test Key Vault connection)
   - `01_extraction.py` (extract data from API â†’ Snowflake Bronze)
   - `02_transformation.py` (transform Bronze â†’ Silver â†’ Gold)
   - `03_loading.py` (validation and metadata)

ğŸ” **Security:** Credentials are stored in `config/credentials.yaml` (not committed to Git)

---

## ğŸ“Š Data Structure

### Bronze Layer

**Table:** `BRONZE.BRONZE_CRYPTO_RAW`

- `id` (STRING): UUID
- `payload` (VARIANT): Complete JSON from API
- `extracted_at` (TIMESTAMP): Extraction timestamp
- `run_id` (STRING): Execution ID
- `processed` (BOOLEAN): Processing flag

### Silver Layer

**Table:** `SILVER.silver_crypto_clean`

- `coin_id`, `symbol`, `name`
- `current_price`, `market_cap`, `total_volume`
- `is_current` (BOOLEAN): Current record
- `valid_from`, `valid_to` (TIMESTAMP): SCD Type 2

### Gold Layer

**Table:** `GOLD.gold_crypto_metrics`

- `metric_date` (DATE)
- `market_cap_category` (STRING): LARGE/MID/SMALL_CAP
- `num_coins`, `total_market_cap`, `avg_market_cap`
- Aggregated metrics by category

---

## ğŸ® Usage

### Manual Execution

```bash
# Databricks: execute notebooks in order
1. 01_extraction.py
2. 02_transformation.py
3. 03_loading.py
```

### SQL Queries

```sql
-- View current data (Silver)
SELECT * FROM SILVER.v_current_market_state LIMIT 10;

-- View aggregated metrics (Gold)
SELECT * FROM GOLD.v_market_summary WHERE metric_date = CURRENT_DATE();

-- View Bronze raw
SELECT payload:symbol::STRING, payload:current_price::FLOAT 
FROM BRONZE.BRONZE_CRYPTO_RAW LIMIT 10;
```

---

## ğŸ”§ Configuration

### Azure Key Vault

```python
# config_loader.py automatically detects:
os.environ['AZURE_TENANT_ID']
os.environ['AZURE_CLIENT_ID']
os.environ['AZURE_CLIENT_SECRET']

# Usage:
snowflake_config = get_snowflake_credentials_from_keyvault("kv-crypto-pipeline")
```

### Snowflake Connection

```python
conn = snowflake.connector.connect(
    account=snowflake_config['account'],
    user=snowflake_config['user'],
    password=snowflake_config['password'],
    warehouse='SNOWFLAKE_LEARNING_WH',
    database='CRYPTO_DB'
)
```

---

## ğŸ“ˆ Monitoring

### Quality Views

```sql
SELECT * FROM SILVER.v_data_quality_metrics;
SELECT * FROM SILVER.v_pipeline_execution_history;
SELECT * FROM BRONZE.v_bronze_extraction_stats;
```

### Stored Procedures

```sql
CALL BRONZE.sp_mark_records_processed('run_id');
CALL BRONZE.sp_archive_old_bronze_data(90);
CALL SILVER.sp_refresh_daily_summary();
```

---

## ğŸ“š Technologies

| Category | Technology | Version |
|-----------|-----------|--------|
| Language | Python | 3.9+ |
| Processing | PySpark | 3.5+ |
| Compute | Databricks Community | - |
| Warehouse | Snowflake | Trial |
| Secrets | Azure Key Vault | - |
| API | CoinGecko | v3 |

---

## ğŸ”’ Security

- âœ… Credentials in Azure Key Vault
- âœ… Service Principal for authentication
- âœ… RBAC
- âœ… Secrets not versioned
- âœ… HTTPS connections

---

## ğŸ“ Dependencies

```txt
azure-identity==1.14.0
azure-keyvault-secrets==4.7.0
snowflake-connector-python[pandas]==3.6.0
requests==2.31.0
pyyaml==6.0
tenacity==8.2.3
```

---

## ğŸ‘¤ Author

**Eric M.**  
Data Engineer Portfolio Project

---

## ğŸ“„ License

MIT License

---

â­ **If this project was useful, consider giving it a star!**
